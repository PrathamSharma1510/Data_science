{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Probability Mass Function (PMF) and Probability Density Function (PDF) are concepts used in probability theory to describe how probabilities are distributed over different outcomes of a random variable. They differ based on whether the random variable is discrete or continuous.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "Applies to: Discrete Random Variables (variables that take specific, separate values).\n",
    "Definition: PMF gives the probability that a discrete random variable is exactly equal to some value.\n",
    "Example: Tossing a fair six-sided die. The PMF gives the probability of each outcome (1, 2, 3, 4, 5, or 6), which is \n",
    "1/6 for a fair die.\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "Applies to: Continuous Random Variables (variables that take any value in a range).\n",
    "Definition: PDF represents how probabilities are distributed over a continuous range of values. It gives the probability density at a point, which is used to calculate the probability over an interval.\n",
    "Example: The height of adults in a city. The PDF might show that most people are around a certain height, with fewer people taller or shorter. The probability of someone being exactly 170 cm tall is not given by the PDF; instead, the PDF would be used to find the probability of someone being between, say, 170 and 171 cm tall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The Cumulative Density Function (CDF) is a fundamental concept in probability theory and statistics that describes the cumulative probability associated with a random variable.\n",
    "Applies to Both Discrete and Continuous Random Variables.\n",
    "\n",
    "Example:\n",
    "Discrete Example: Consider a six-sided fair die. The CDF at 4 would be the probability of rolling a 4 or less, which is 4/6 or about 0.67.\n",
    "\n",
    "Continuous Example: For a normal distribution, the CDF at a certain point (e.g.z) gives the area under the curve to the left of z. If z is the mean, the CDF would be 0.5, indicating a 50% chance of drawing a value below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normal distribution is used for continuous distributions where the distribution is infinite. It is used in many filds such as :-\n",
    "1) HEIGHT/WEIGHT measurements: The popluation heigth follows a normal distribution which are maximum at the average and less at the ends.\n",
    "2) Test Scores \n",
    "3) Stock Market Returns\n",
    "\n",
    "Parameters of the Normal Distribution:\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ).\n",
    "\n",
    "Mean (μ):\n",
    "\n",
    "The mean determines the center of the distribution.\n",
    "In a normal distribution, it is the peak point where the curve is highest.\n",
    "Standard Deviation (σ):\n",
    "\n",
    "The standard deviation determines the spread of the distribution.\n",
    "A larger standard deviation means the data is more spread out, resulting in a flatter and wider curve.\n",
    "A smaller standard deviation means the data is more clustered around the mean, resulting in a steeper and narrower curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Imporatnce of normal distribution :-\n",
    "1) Symmetry and Predictability: The normal distribution is symmetric around the mean, making it predictable and easy to interpret. Most values cluster around the central peak, with probabilities decreasing symmetrically as you move away from the mean.\n",
    "\n",
    "2) Standardization and Z-Scores: The properties of the normal distribution allow for the creation of standard scores (or z-scores), which are useful for comparing data from different distributions.\n",
    "\n",
    "3) Error Distribution: In many natural and measurement processes, errors or deviations from the mean are often normally distributed, which aids in quality control and reliability assessments.\n",
    "\n",
    "Examples:-\n",
    "1) Height and Weight Measurements: \n",
    "2) Performance Measures: Test scores\n",
    "3) Finance: Daily or monthly returns on stocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bernauli Distribution is a type of discrete probability distribution for random variable which take value 1 with probability of p and value 0 with probability of 1-p.\n",
    "\n",
    "Diffrence between Bernoulli Distribution: A single trial with two possible outcomes (e.g., a single coin flip).\n",
    "Binomial Distribution: Multiple trials, each of which is a Bernoulli trial (e.g., flipping a coin ten times and counting the number of heads).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15865525393145707"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stat\n",
    "mean=50\n",
    "sd=10\n",
    "# normal distribution\n",
    "# distributed, what is the probability that a randomly selected observation will be greater\n",
    "# than 60?\n",
    "ans=1-stat.norm.cdf(60,mean,sd)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. \n",
    "A uniform distribution, in both its discrete and continuous forms, describes a scenario where all possible outcomes within a specific range have an equal probability of occurring. Basically, it's like flipping a fair coin – heads and tails have the same chance of landing.\n",
    "\n",
    "Discrete Uniform Distribution:\n",
    "\n",
    "Imagine picking a random number from a hat containing only the numbers 1 to 5. Since all five numbers are present, each one has an equal probability (1/5) of being drawn. This is a discrete uniform distribution because the possible outcomes are finite and equally likely.\n",
    "Continuous Uniform Distribution:\n",
    "\n",
    "Picture throwing a dart at a rectangular dartboard marked from 0 to 10 on both axes. No matter where the dart lands within this rectangle, it has the same probability of hitting any particular point. This is a continuous uniform distribution because the possible outcomes are infinite (any point within the rectangle) and still have equal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. \n",
    "A z-score tells you how far (in standard deviations) a data point falls from the mean, like measuring with a \"ruler of standard deviations.\" It's important because it lets you:\n",
    "\n",
    "Compare data across different sets, even if they use different units.\n",
    "Spot outliers that deviate significantly from the typical pattern.\n",
    "Check for normality in your data (like making sure everyone's height falls within a reasonable range).\n",
    "Prepare data for machine learning by making sure all features are on the same scale.\n",
    "Basically, z-scores are like handy translators – they turn data chaos into clear, comparable information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. The Central Limit Theorem: \"No matter how weird your data is, if you grab enough of it, its average tends to become normal!\" It basically says that if you take many small random samples from any population (even non-normal!), the distribution of those sample means will approach a bell curve as your sample size grows.\n",
    "\n",
    "\n",
    "Predicting averages: We can estimate population averages with more confidence from smaller samples.\n",
    "Hypothesis testing: It helps justify using normal-distribution-based tests even with non-normal data (assuming sufficient sample size).\n",
    "Understanding randomness: It shows how chaos (individual data points) can lead to order (normal distribution) in the big picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. The Central Limit Theorem (CLT) is a fundamental principle in statistics with several key assumptions:\n",
    "\n",
    "Independence: The sampled observations must be independent of each other. This means the selection of one observation does not influence or affect the selection of another.\n",
    "Random Sampling: The data must be collected through a process of random sampling or random experiment.\n",
    "Distribution: The CLT applies regardless of the shape of the population distribution, but the underlying distribution should be fixed and not changing.\n",
    "Sample Size: The sample size should be sufficiently large. While there is no strict rule for what constitutes \"large,\" a common guideline is a sample size of at least 30. Larger samples lead to a more normal distribution of sample means.\n",
    "Identically Distributed: The random variables should be identically distributed, meaning they should have the same probability distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
